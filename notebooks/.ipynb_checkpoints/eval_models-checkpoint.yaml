name: Eval models
description: Evaluate different models on holdout dataset to see which model performs
  the best
inputs:
- {name: feature_data_path, type: String}
- {name: vanilla_model_store_path}
- {name: tuned_model_store_path, type: String}
- {name: holdout_engine, type: Integer}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'scikit-learn' 'fastparquet' 'fsspec' 'gcsfs' 'google-cloud-storage' || PIP_DISABLE_PIP_VERSION_CHECK=1
      python3 -m pip install --quiet --no-warn-script-location 'scikit-learn' 'fastparquet'
      'fsspec' 'gcsfs' 'google-cloud-storage' --user) && "$0" "$@"
    - python3
    - -u
    - -c
    - "def eval_models(feature_data_path, vanilla_model_store_path, tuned_model_store_path,\
      \ holdout_engine):\n    '''Evaluate different models on holdout dataset to see\
      \ which model performs the best'''\n    import json\n    import pandas as pd\n\
      \    from io import BytesIO\n    from datetime import datetime, timedelta\n\
      \    import _pickle as cPickle # save ML model\n    from google.cloud import\
      \ storage # save the model to GCS\n    from sklearn.ensemble import RandomForestRegressor\n\
      \    from sklearn.metrics import mean_absolute_error, mean_squared_error\n \
      \   from sklearn.model_selection import train_test_split\n    from sklearn.model_selection\
      \ import RandomizedSearchCV\n    from sklearn.model_selection import GridSearchCV\n\
      \    from urllib.parse import urlparse\n    from collections import namedtuple\n\
      \n    # read dataframe\n    complete_df = pd.read_parquet(feature_data_path)\n\
      \n    # this will be our holdout set for validation\n    holdout_df = complete_df.loc[complete_df.engine_id\
      \ == holdout_engine].iloc[:,2:].copy()\n\n    # get x and y\n    x_val, y_val\
      \ = holdout_df.drop('RUL', axis=1), holdout_df['RUL']\n\n    def get_mae(model_path):\n\
      \        '''this function evaluates a model on our holdout dataset given just\
      \ the model path'''\n        parse = urlparse(url=model_path, allow_fragments=False)\n\
      \n        if parse.path[0] =='/':\n            model_path = parse.path[1:]\n\
      \n        client = storage.Client()\n        bucket = client.get_bucket(parse.netloc)\n\
      \        blob = bucket.get_blob(model_path)\n        if blob is None:\n    \
      \        raise AttributeError('No files to download') \n        model_bytestream\
      \ = BytesIO(blob.download_as_string())\n        model = cPickle.load(model_bytestream)\n\
      \        predictions = model.predict(x_val)\n        return mean_absolute_error(y_val,\
      \ predictions)\n\n    Models = namedtuple('Model', 'type score path')\n    m_list\
      \ = list()\n\n    vanilla_mae = get_mae(vanilla_model_store_path)\n    m_list.append(Models('vanilla',\
      \ vanilla_mae, vanilla_model_store_path))\n\n    tuned_mae = get_mae(tuned_model_store_path)\n\
      \    m_list.append(Models('tuned', tuned_mae, tuned_model_store_path))\n\n \
      \   max_score = max([model.score for model in m_list])\n    max_score_index\
      \ = [model.score for model in m_list].index(max_score)\n    print('Best Model:\
      \ ', m_list[max_score_index])\n    path = m_list[max_score_index].path\n   \
      \ return path\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Eval\
      \ models', description='Evaluate different models on holdout dataset to see\
      \ which model performs the best')\n_parser.add_argument(\"--feature-data-path\"\
      , dest=\"feature_data_path\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--vanilla-model-store-path\", dest=\"vanilla_model_store_path\"\
      , type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --tuned-model-store-path\", dest=\"tuned_model_store_path\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--holdout-engine\", dest=\"\
      holdout_engine\", type=int, required=True, default=argparse.SUPPRESS)\n_parsed_args\
      \ = vars(_parser.parse_args())\n\n_outputs = eval_models(**_parsed_args)\n"
    args:
    - --feature-data-path
    - {inputValue: feature_data_path}
    - --vanilla-model-store-path
    - {inputValue: vanilla_model_store_path}
    - --tuned-model-store-path
    - {inputValue: tuned_model_store_path}
    - --holdout-engine
    - {inputValue: holdout_engine}
